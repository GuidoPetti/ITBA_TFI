{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRABAJO FINAL INTEGRADOR\n",
    "\n",
    "### NOMBRE: GUIDO PETTINARI\n",
    "\n",
    "### TUTOR: VALERIA SOLIANI\n",
    "\n",
    "### UNIVERSIDAD: INSTITUTO TECNOLOGICO DE BUENOS AIRES (ITBA)\n",
    "\n",
    "**El Trabajo se dividirá en**:\n",
    "\n",
    "    1) Análisis Exploratorio Descriptivo\n",
    "    2) Feature Engineering o Preparación de Datos\n",
    "    3) Modelos Predictivos: Probaremos diferentes algoritmos predictivos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score,precision_score,recall_score,roc_auc_score,make_scorer,f1_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from mlxtend.evaluate import lift_score\n",
    "import csv\n",
    "from funpymodeling.exploratory import status"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load CSVs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_base = pd.read_csv('data_base.csv')\n",
    "data_ohe = pd.read_csv('data_ohe.csv')\n",
    "data_ohe_corr = pd.read_csv('data_ohe_corr.csv')\n",
    "data_ohe_out = pd.read_csv('data_ohe_out.csv')\n",
    "data_ohe_corr_out = pd.read_csv('data_ohe_out_corr.csv')\n",
    "data_out = pd.read_csv('data_out.csv')\n",
    "data_corr = pd.read_csv('data_corr.csv')\n",
    "data_out_corr = pd.read_csv('data_out_corr.csv')\n",
    "data_index = pd.read_csv('data_index.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split All DF in Train and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_base_X = data_base.drop(['MonthlyIncome_cat_encode'],axis=1)\n",
    "data_base_y = data_base[['MonthlyIncome_cat_encode']]\n",
    "data_ohe_X = data_ohe.drop(['MonthlyIncome_cat_encode'],axis=1)\n",
    "data_ohe_y = data_ohe[['MonthlyIncome_cat_encode']]\n",
    "data_ohe_corr_X = data_ohe_corr.drop(['MonthlyIncome_cat_encode'],axis=1)\n",
    "data_ohe_corr_y = data_ohe_corr[['MonthlyIncome_cat_encode']]\n",
    "data_ohe_out_X = data_ohe_out.drop(['MonthlyIncome_cat_encode'],axis=1)\n",
    "data_ohe_out_y = data_ohe_out[['MonthlyIncome_cat_encode']]\n",
    "data_ohe_corr_out_X = data_ohe_corr_out.drop(['MonthlyIncome_cat_encode'],axis=1)\n",
    "data_ohe_corr_out_y = data_ohe_corr_out[['MonthlyIncome_cat_encode']]\n",
    "data_out_X = data_out.drop(['MonthlyIncome_cat_encode'],axis=1)\n",
    "data_out_y = data_out[['MonthlyIncome_cat_encode']]\n",
    "data_corr_X = data_corr.drop(['MonthlyIncome_cat_encode'],axis=1)\n",
    "data_corr_y = data_corr[['MonthlyIncome_cat_encode']]\n",
    "data_out_corr_X = data_out_corr.drop(['MonthlyIncome_cat_encode'],axis=1)\n",
    "data_out_corr_y = data_out_corr[['MonthlyIncome_cat_encode']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_base\n",
    "\n",
    "data_base_X_train, data_base_X_test, data_base_y_train, \\\n",
    "                                     data_base_y_test = train_test_split(data_base_X, data_base_y, test_size=0.3, random_state=42)\n",
    "\n",
    "#data_ohe\n",
    "data_ohe_X_train, data_ohe_X_test, data_ohe_y_train, \\\n",
    "                                   data_ohe_y_test = train_test_split(data_ohe_X, data_ohe_y, test_size=0.3, random_state=42)\n",
    "\n",
    "#data_ohe_corr\n",
    "data_ohe_corr_X_train, data_ohe_corr_X_test, data_ohe_corr_y_train, \\\n",
    "                       data_ohe_corr_y_test = train_test_split(data_ohe_corr_X, data_ohe_corr_y, test_size=0.3, random_state=42)\n",
    "\n",
    "# data_ohe_out\n",
    "data_ohe_out_X_train, data_ohe_out_X_test, data_ohe_out_y_train, \\\n",
    "                      data_ohe_out_y_test = train_test_split(data_ohe_out_X, data_ohe_out_y, test_size=0.3, random_state=42)\n",
    "\n",
    "# data_ohe_corr_out\n",
    "data_ohe_corr_out_X_train, data_ohe_corr_out_X_test, data_ohe_corr_out_y_train, \\\n",
    "                           data_ohe_corr_out_y_test = train_test_split(data_ohe_corr_out_X, data_ohe_corr_out_y, test_size=0.3, random_state=42)\n",
    "\n",
    "# data_out\n",
    "data_out_X_train, data_out_X_test, data_out_y_train, \\\n",
    "                           data_out_y_test = train_test_split(data_out_X, data_out_y, test_size=0.3, random_state=42)\n",
    "\n",
    "# data_corr\n",
    "data_corr_X_train, data_corr_X_test, data_corr_y_train, \\\n",
    "                           data_corr_y_test = train_test_split(data_corr_X, data_corr_y, test_size=0.3, random_state=42)\n",
    "\n",
    "# data_out_corr\n",
    "data_out_corr_X_train, data_out_corr_X_test, data_out_corr_y_train, \\\n",
    "                           data_out_corr_y_test = train_test_split(data_out_corr_X, data_out_corr_y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>DistanceFromHome</th>\n",
       "      <th>Education</th>\n",
       "      <th>EnvironmentSatisfaction</th>\n",
       "      <th>JobInvolvement</th>\n",
       "      <th>JobLevel</th>\n",
       "      <th>JobSatisfaction</th>\n",
       "      <th>NumCompaniesWorked</th>\n",
       "      <th>PerformanceRating</th>\n",
       "      <th>RelationshipSatisfaction</th>\n",
       "      <th>...</th>\n",
       "      <th>OverTime_Yes</th>\n",
       "      <th>MaritalStatus_Married</th>\n",
       "      <th>MaritalStatus_Single</th>\n",
       "      <th>Attrition_Yes</th>\n",
       "      <th>Department_Research &amp; Development</th>\n",
       "      <th>EducationField_Life Sciences</th>\n",
       "      <th>EducationField_Marketing</th>\n",
       "      <th>EducationField_Medical</th>\n",
       "      <th>EducationField_Other</th>\n",
       "      <th>EducationField_Technical Degree</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1029.000000</td>\n",
       "      <td>1029.000000</td>\n",
       "      <td>1029.000000</td>\n",
       "      <td>1029.000000</td>\n",
       "      <td>1029.000000</td>\n",
       "      <td>1029.000000</td>\n",
       "      <td>1029.000000</td>\n",
       "      <td>1029.000000</td>\n",
       "      <td>1029.000000</td>\n",
       "      <td>1029.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1029.000000</td>\n",
       "      <td>1029.000000</td>\n",
       "      <td>1029.000000</td>\n",
       "      <td>1029.000000</td>\n",
       "      <td>1029.000000</td>\n",
       "      <td>1029.000000</td>\n",
       "      <td>1029.000000</td>\n",
       "      <td>1029.000000</td>\n",
       "      <td>1029.000000</td>\n",
       "      <td>1029.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>36.910593</td>\n",
       "      <td>9.364431</td>\n",
       "      <td>2.892128</td>\n",
       "      <td>2.683188</td>\n",
       "      <td>2.713314</td>\n",
       "      <td>2.043732</td>\n",
       "      <td>2.712342</td>\n",
       "      <td>2.546161</td>\n",
       "      <td>3.159378</td>\n",
       "      <td>2.689990</td>\n",
       "      <td>...</td>\n",
       "      <td>0.289602</td>\n",
       "      <td>0.464529</td>\n",
       "      <td>0.310982</td>\n",
       "      <td>0.171040</td>\n",
       "      <td>0.656948</td>\n",
       "      <td>0.413994</td>\n",
       "      <td>0.106900</td>\n",
       "      <td>0.318756</td>\n",
       "      <td>0.064140</td>\n",
       "      <td>0.079689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>9.263531</td>\n",
       "      <td>8.222723</td>\n",
       "      <td>1.053541</td>\n",
       "      <td>1.096829</td>\n",
       "      <td>0.710146</td>\n",
       "      <td>1.118918</td>\n",
       "      <td>1.096889</td>\n",
       "      <td>2.273399</td>\n",
       "      <td>0.366206</td>\n",
       "      <td>1.077767</td>\n",
       "      <td>...</td>\n",
       "      <td>0.453798</td>\n",
       "      <td>0.498983</td>\n",
       "      <td>0.463120</td>\n",
       "      <td>0.376727</td>\n",
       "      <td>0.474959</td>\n",
       "      <td>0.492787</td>\n",
       "      <td>0.309136</td>\n",
       "      <td>0.466221</td>\n",
       "      <td>0.245121</td>\n",
       "      <td>0.270943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>18.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>30.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>35.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>43.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>60.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Age  DistanceFromHome    Education  EnvironmentSatisfaction  \\\n",
       "count  1029.000000       1029.000000  1029.000000              1029.000000   \n",
       "mean     36.910593          9.364431     2.892128                 2.683188   \n",
       "std       9.263531          8.222723     1.053541                 1.096829   \n",
       "min      18.000000          1.000000     1.000000                 1.000000   \n",
       "25%      30.000000          2.000000     2.000000                 2.000000   \n",
       "50%      35.000000          7.000000     3.000000                 3.000000   \n",
       "75%      43.000000         14.000000     4.000000                 4.000000   \n",
       "max      60.000000         29.000000     5.000000                 4.000000   \n",
       "\n",
       "       JobInvolvement     JobLevel  JobSatisfaction  NumCompaniesWorked  \\\n",
       "count     1029.000000  1029.000000      1029.000000         1029.000000   \n",
       "mean         2.713314     2.043732         2.712342            2.546161   \n",
       "std          0.710146     1.118918         1.096889            2.273399   \n",
       "min          1.000000     1.000000         1.000000            0.000000   \n",
       "25%          2.000000     1.000000         2.000000            1.000000   \n",
       "50%          3.000000     2.000000         3.000000            1.000000   \n",
       "75%          3.000000     3.000000         4.000000            4.000000   \n",
       "max          4.000000     5.000000         4.000000            7.000000   \n",
       "\n",
       "       PerformanceRating  RelationshipSatisfaction  ...  OverTime_Yes  \\\n",
       "count        1029.000000               1029.000000  ...   1029.000000   \n",
       "mean            3.159378                  2.689990  ...      0.289602   \n",
       "std             0.366206                  1.077767  ...      0.453798   \n",
       "min             3.000000                  1.000000  ...      0.000000   \n",
       "25%             3.000000                  2.000000  ...      0.000000   \n",
       "50%             3.000000                  3.000000  ...      0.000000   \n",
       "75%             3.000000                  4.000000  ...      1.000000   \n",
       "max             4.000000                  4.000000  ...      1.000000   \n",
       "\n",
       "       MaritalStatus_Married  MaritalStatus_Single  Attrition_Yes  \\\n",
       "count            1029.000000           1029.000000    1029.000000   \n",
       "mean                0.464529              0.310982       0.171040   \n",
       "std                 0.498983              0.463120       0.376727   \n",
       "min                 0.000000              0.000000       0.000000   \n",
       "25%                 0.000000              0.000000       0.000000   \n",
       "50%                 0.000000              0.000000       0.000000   \n",
       "75%                 1.000000              1.000000       0.000000   \n",
       "max                 1.000000              1.000000       1.000000   \n",
       "\n",
       "       Department_Research & Development  EducationField_Life Sciences  \\\n",
       "count                        1029.000000                   1029.000000   \n",
       "mean                            0.656948                      0.413994   \n",
       "std                             0.474959                      0.492787   \n",
       "min                             0.000000                      0.000000   \n",
       "25%                             0.000000                      0.000000   \n",
       "50%                             1.000000                      0.000000   \n",
       "75%                             1.000000                      1.000000   \n",
       "max                             1.000000                      1.000000   \n",
       "\n",
       "       EducationField_Marketing  EducationField_Medical  EducationField_Other  \\\n",
       "count               1029.000000             1029.000000           1029.000000   \n",
       "mean                   0.106900                0.318756              0.064140   \n",
       "std                    0.309136                0.466221              0.245121   \n",
       "min                    0.000000                0.000000              0.000000   \n",
       "25%                    0.000000                0.000000              0.000000   \n",
       "50%                    0.000000                0.000000              0.000000   \n",
       "75%                    0.000000                1.000000              0.000000   \n",
       "max                    1.000000                1.000000              1.000000   \n",
       "\n",
       "       EducationField_Technical Degree  \n",
       "count                      1029.000000  \n",
       "mean                          0.079689  \n",
       "std                           0.270943  \n",
       "min                           0.000000  \n",
       "25%                           0.000000  \n",
       "50%                           0.000000  \n",
       "75%                           0.000000  \n",
       "max                           1.000000  \n",
       "\n",
       "[8 rows x 43 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_ohe_X_train.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': range(2, 100, 10), 'max_features': ['auto', 'sqrt'], 'max_depth': range(2, 42, 2), 'min_samples_split': [2, 4, 6, 8, 10], 'min_samples_leaf': [2, 4, 6, 8, 10]}\n"
     ]
    }
   ],
   "source": [
    "# Number of trees in random forest\n",
    "#n_estimators = [int(x) for x in np.linspace(start = 10, stop = 100, num = 50)]\n",
    "n_estimators = range(2, 100, 10)\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = range(2, 42, 2)\n",
    "\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2,4,6,8,10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [2,4,6,8,10]\n",
    "# Method of selecting samples for training each tree\n",
    "#bootstrap = [True, False]\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf}\n",
    "               #'bootstrap': bootstrap}\n",
    "print(random_grid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "scoring = {'lift':make_scorer(lift_score),\n",
    "           'precision': make_scorer(precision_score, average = 'macro'),\n",
    "           'f1_score':make_scorer(f1_score, average='macro'),\n",
    "           'accuracy': make_scorer(accuracy_score),\n",
    "           'recall':make_scorer(recall_score,average='macro'),\n",
    "           'roc_auc_ovr':'roc_auc_ovr'}\n",
    "\n",
    "# Use the random grid to search for best hyperparameters\n",
    "# First create the base model to tune\n",
    "rf = RandomForestClassifier()\n",
    "# Random search of parameters, using 3 fold cross validation, \n",
    "# search across 100 different combinations, and use all available cores\n",
    "rf_random = GridSearchCV(estimator = rf, \n",
    "                               param_grid = random_grid,\n",
    "                               scoring = scoring,\n",
    "                               refit='lift',\n",
    "                               cv = 5, \n",
    "                               verbose=1, \n",
    "                               n_jobs = -1)\n",
    "\n",
    "\n",
    "# list dataframes train that Random Forest accepts\n",
    "list_dataframes_train = [#[data_base_X_train, data_base_X_test],\n",
    "                         [data_ohe_X_train, data_ohe_y_train],\n",
    "                         [data_ohe_corr_X_train, data_ohe_corr_y_train],\n",
    "                         [data_ohe_out_X_train, data_ohe_out_y_train],\n",
    "                         [data_ohe_corr_out_X_train, data_ohe_corr_out_y_train]\n",
    "                         #[data_out_X, data_out_y],\n",
    "                         #[data_corr_X, data_corr_y],\n",
    "                         #[data_out_corr_X, data_out_corr_y]\n",
    "                         ]\n",
    "\n",
    "# list dataframes train that Random Forest accepts\n",
    "list_dataframes_test = [#[data_base_X_train, data_base_X_test],\n",
    "                         [data_ohe_X_test, data_ohe_y_test],\n",
    "                         [data_ohe_corr_X_test, data_ohe_corr_y_test],\n",
    "                         [data_ohe_out_X_test, data_ohe_out_y_test],\n",
    "                         [data_ohe_corr_out_X_test, data_ohe_corr_out_y_test]\n",
    "                         #[data_out_X, data_out_y],\n",
    "                         #[data_corr_X, data_corr_y],\n",
    "                         #[data_out_corr_X, data_out_corr_y]\n",
    "                         ]\n",
    "\n",
    "\n",
    "list_dataframes_names = ['data_ohe','data_ohe_corr','data_ohe_out','data_ohe_corr_out']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10000 candidates, totalling 50000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   11.2s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:   20.8s\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:   34.0s\n",
      "[Parallel(n_jobs=-1)]: Done 784 tasks      | elapsed:   55.4s\n",
      "[Parallel(n_jobs=-1)]: Done 1234 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 1784 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done 2434 tasks      | elapsed:  2.7min\n",
      "[Parallel(n_jobs=-1)]: Done 3184 tasks      | elapsed:  3.7min\n",
      "[Parallel(n_jobs=-1)]: Done 4034 tasks      | elapsed:  4.6min\n",
      "[Parallel(n_jobs=-1)]: Done 4984 tasks      | elapsed:  5.6min\n",
      "[Parallel(n_jobs=-1)]: Done 6034 tasks      | elapsed:  6.6min\n",
      "[Parallel(n_jobs=-1)]: Done 7184 tasks      | elapsed:  7.8min\n",
      "[Parallel(n_jobs=-1)]: Done 8434 tasks      | elapsed:  9.3min\n",
      "[Parallel(n_jobs=-1)]: Done 9784 tasks      | elapsed: 11.0min\n",
      "[Parallel(n_jobs=-1)]: Done 11234 tasks      | elapsed: 12.6min\n",
      "[Parallel(n_jobs=-1)]: Done 12784 tasks      | elapsed: 14.5min\n",
      "[Parallel(n_jobs=-1)]: Done 14434 tasks      | elapsed: 16.4min\n",
      "[Parallel(n_jobs=-1)]: Done 16184 tasks      | elapsed: 18.5min\n",
      "[Parallel(n_jobs=-1)]: Done 18034 tasks      | elapsed: 20.7min\n",
      "[Parallel(n_jobs=-1)]: Done 19984 tasks      | elapsed: 22.9min\n",
      "[Parallel(n_jobs=-1)]: Done 22034 tasks      | elapsed: 25.3min\n",
      "[Parallel(n_jobs=-1)]: Done 24184 tasks      | elapsed: 27.6min\n",
      "[Parallel(n_jobs=-1)]: Done 26434 tasks      | elapsed: 30.0min\n",
      "[Parallel(n_jobs=-1)]: Done 28784 tasks      | elapsed: 32.4min\n",
      "[Parallel(n_jobs=-1)]: Done 31234 tasks      | elapsed: 35.0min\n",
      "[Parallel(n_jobs=-1)]: Done 33784 tasks      | elapsed: 37.7min\n",
      "[Parallel(n_jobs=-1)]: Done 36434 tasks      | elapsed: 40.7min\n",
      "[Parallel(n_jobs=-1)]: Done 39184 tasks      | elapsed: 43.6min\n",
      "[Parallel(n_jobs=-1)]: Done 42034 tasks      | elapsed: 46.7min\n",
      "[Parallel(n_jobs=-1)]: Done 44984 tasks      | elapsed: 49.8min\n",
      "[Parallel(n_jobs=-1)]: Done 48034 tasks      | elapsed: 52.9min\n",
      "[Parallel(n_jobs=-1)]: Done 50000 out of 50000 | elapsed: 55.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10000 candidates, totalling 50000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  52 tasks      | elapsed:    2.9s\n",
      "[Parallel(n_jobs=-1)]: Done 248 tasks      | elapsed:   13.4s\n",
      "[Parallel(n_jobs=-1)]: Done 498 tasks      | elapsed:   25.8s\n",
      "[Parallel(n_jobs=-1)]: Done 848 tasks      | elapsed:   44.6s\n",
      "[Parallel(n_jobs=-1)]: Done 1298 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 1848 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done 2498 tasks      | elapsed:  2.3min\n",
      "[Parallel(n_jobs=-1)]: Done 3248 tasks      | elapsed:  3.0min\n",
      "[Parallel(n_jobs=-1)]: Done 4098 tasks      | elapsed:  3.8min\n",
      "[Parallel(n_jobs=-1)]: Done 5048 tasks      | elapsed:  4.7min\n",
      "[Parallel(n_jobs=-1)]: Done 6098 tasks      | elapsed:  5.7min\n",
      "[Parallel(n_jobs=-1)]: Done 7248 tasks      | elapsed:  6.9min\n",
      "[Parallel(n_jobs=-1)]: Done 8498 tasks      | elapsed:  8.1min\n",
      "[Parallel(n_jobs=-1)]: Done 9848 tasks      | elapsed:  9.4min\n",
      "[Parallel(n_jobs=-1)]: Done 11298 tasks      | elapsed: 10.9min\n",
      "[Parallel(n_jobs=-1)]: Done 12848 tasks      | elapsed: 12.5min\n",
      "[Parallel(n_jobs=-1)]: Done 14498 tasks      | elapsed: 14.0min\n",
      "[Parallel(n_jobs=-1)]: Done 16248 tasks      | elapsed: 15.7min\n",
      "[Parallel(n_jobs=-1)]: Done 18098 tasks      | elapsed: 17.6min\n",
      "[Parallel(n_jobs=-1)]: Done 20048 tasks      | elapsed: 19.6min\n",
      "[Parallel(n_jobs=-1)]: Done 22098 tasks      | elapsed: 21.5min\n",
      "[Parallel(n_jobs=-1)]: Done 24248 tasks      | elapsed: 23.7min\n",
      "[Parallel(n_jobs=-1)]: Done 26498 tasks      | elapsed: 25.9min\n",
      "[Parallel(n_jobs=-1)]: Done 28848 tasks      | elapsed: 28.4min\n",
      "[Parallel(n_jobs=-1)]: Done 31298 tasks      | elapsed: 30.6min\n",
      "[Parallel(n_jobs=-1)]: Done 33848 tasks      | elapsed: 33.0min\n",
      "[Parallel(n_jobs=-1)]: Done 36498 tasks      | elapsed: 35.8min\n",
      "[Parallel(n_jobs=-1)]: Done 39248 tasks      | elapsed: 38.5min\n",
      "[Parallel(n_jobs=-1)]: Done 42098 tasks      | elapsed: 41.4min\n",
      "[Parallel(n_jobs=-1)]: Done 45048 tasks      | elapsed: 44.3min\n",
      "[Parallel(n_jobs=-1)]: Done 48098 tasks      | elapsed: 47.3min\n",
      "[Parallel(n_jobs=-1)]: Done 50000 out of 50000 | elapsed: 49.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10000 candidates, totalling 50000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  52 tasks      | elapsed:    2.3s\n",
      "[Parallel(n_jobs=-1)]: Done 352 tasks      | elapsed:   16.9s\n",
      "[Parallel(n_jobs=-1)]: Done 722 tasks      | elapsed:   34.7s\n",
      "[Parallel(n_jobs=-1)]: Done 1072 tasks      | elapsed:   53.7s\n",
      "[Parallel(n_jobs=-1)]: Done 1522 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 2072 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done 2722 tasks      | elapsed:  2.3min\n",
      "[Parallel(n_jobs=-1)]: Done 3472 tasks      | elapsed:  3.0min\n",
      "[Parallel(n_jobs=-1)]: Done 4322 tasks      | elapsed:  3.8min\n",
      "[Parallel(n_jobs=-1)]: Done 5272 tasks      | elapsed:  4.6min\n",
      "[Parallel(n_jobs=-1)]: Done 6322 tasks      | elapsed:  5.6min\n",
      "[Parallel(n_jobs=-1)]: Done 7472 tasks      | elapsed:  6.7min\n",
      "[Parallel(n_jobs=-1)]: Done 8722 tasks      | elapsed:  8.0min\n",
      "[Parallel(n_jobs=-1)]: Done 10072 tasks      | elapsed:  9.3min\n",
      "[Parallel(n_jobs=-1)]: Done 11522 tasks      | elapsed: 10.7min\n",
      "[Parallel(n_jobs=-1)]: Done 13072 tasks      | elapsed: 12.3min\n",
      "[Parallel(n_jobs=-1)]: Done 14722 tasks      | elapsed: 13.9min\n",
      "[Parallel(n_jobs=-1)]: Done 16472 tasks      | elapsed: 15.7min\n",
      "[Parallel(n_jobs=-1)]: Done 18322 tasks      | elapsed: 17.5min\n",
      "[Parallel(n_jobs=-1)]: Done 20272 tasks      | elapsed: 19.6min\n",
      "[Parallel(n_jobs=-1)]: Done 22322 tasks      | elapsed: 21.5min\n",
      "[Parallel(n_jobs=-1)]: Done 24472 tasks      | elapsed: 23.6min\n",
      "[Parallel(n_jobs=-1)]: Done 26722 tasks      | elapsed: 25.5min\n",
      "[Parallel(n_jobs=-1)]: Done 29072 tasks      | elapsed: 27.6min\n",
      "[Parallel(n_jobs=-1)]: Done 31522 tasks      | elapsed: 28.9min\n",
      "[Parallel(n_jobs=-1)]: Done 34072 tasks      | elapsed: 30.1min\n",
      "[Parallel(n_jobs=-1)]: Done 36722 tasks      | elapsed: 31.4min\n",
      "[Parallel(n_jobs=-1)]: Done 39472 tasks      | elapsed: 32.7min\n",
      "[Parallel(n_jobs=-1)]: Done 42322 tasks      | elapsed: 34.2min\n",
      "[Parallel(n_jobs=-1)]: Done 45272 tasks      | elapsed: 35.7min\n",
      "[Parallel(n_jobs=-1)]: Done 48322 tasks      | elapsed: 37.2min\n",
      "[Parallel(n_jobs=-1)]: Done 50000 out of 50000 | elapsed: 38.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10000 candidates, totalling 50000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  52 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=-1)]: Done 352 tasks      | elapsed:    9.0s\n",
      "[Parallel(n_jobs=-1)]: Done 852 tasks      | elapsed:   21.9s\n",
      "[Parallel(n_jobs=-1)]: Done 1552 tasks      | elapsed:   40.3s\n",
      "[Parallel(n_jobs=-1)]: Done 2452 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 3552 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done 4852 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=-1)]: Done 6352 tasks      | elapsed:  2.8min\n",
      "[Parallel(n_jobs=-1)]: Done 8052 tasks      | elapsed:  3.6min\n",
      "[Parallel(n_jobs=-1)]: Done 9952 tasks      | elapsed:  4.6min\n",
      "[Parallel(n_jobs=-1)]: Done 12052 tasks      | elapsed:  5.6min\n",
      "[Parallel(n_jobs=-1)]: Done 14352 tasks      | elapsed:  6.8min\n",
      "[Parallel(n_jobs=-1)]: Done 16852 tasks      | elapsed:  8.1min\n",
      "[Parallel(n_jobs=-1)]: Done 19552 tasks      | elapsed:  9.5min\n",
      "[Parallel(n_jobs=-1)]: Done 22452 tasks      | elapsed: 10.9min\n",
      "[Parallel(n_jobs=-1)]: Done 25552 tasks      | elapsed: 12.5min\n",
      "[Parallel(n_jobs=-1)]: Done 28852 tasks      | elapsed: 14.2min\n",
      "[Parallel(n_jobs=-1)]: Done 32352 tasks      | elapsed: 16.0min\n",
      "[Parallel(n_jobs=-1)]: Done 36052 tasks      | elapsed: 17.9min\n",
      "[Parallel(n_jobs=-1)]: Done 39952 tasks      | elapsed: 19.9min\n",
      "[Parallel(n_jobs=-1)]: Done 44052 tasks      | elapsed: 22.0min\n",
      "[Parallel(n_jobs=-1)]: Done 48352 tasks      | elapsed: 24.2min\n",
      "[Parallel(n_jobs=-1)]: Done 50000 out of 50000 | elapsed: 25.1min finished\n"
     ]
    }
   ],
   "source": [
    "# Fit the random search model\n",
    "df = pd.DataFrame()\n",
    "for i in range(0,len(list_dataframes_train)):\n",
    "    #Entreno sobre mis dataframes train  \n",
    "    rf_random.fit(list_dataframes_train[i][0], list_dataframes_train[i][1].values.ravel())\n",
    "    len_name = len(rf_random.cv_results_['mean_test_accuracy'])\n",
    "    name = [list_dataframes_names[i]]*len_name\n",
    "\n",
    "    train_results = pd.concat([\n",
    "                     pd.DataFrame(name,columns=['dataframe']),\n",
    "                     pd.DataFrame(rf_random.cv_results_['params']),\n",
    "                     pd.DataFrame(rf_random.cv_results_['mean_test_lift'],columns=['lift']),          \n",
    "                     pd.DataFrame(rf_random.cv_results_['mean_test_accuracy'],columns=['accuracy']),\n",
    "                     pd.DataFrame(rf_random.cv_results_['mean_test_precision'],columns=['precision_score']),\n",
    "                     pd.DataFrame(rf_random.cv_results_['mean_test_recall'],columns=['recall']),\n",
    "                     pd.DataFrame(rf_random.cv_results_['mean_test_f1_score'],columns=['f1_score']),\n",
    "                     pd.DataFrame(rf_random.cv_results_['mean_test_roc_auc_ovr'],columns=['roc_auc_ovr'])],axis=1).sort_values('lift',ascending=False)\n",
    "    df = df.append(train_results) \n",
    "df.to_csv('train_rf_results_v2.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A continuación correremos con los parametros que nos dió mejor resultado tanto el training como el testing y los graficaremos \n",
    "# con una curva de ROC\n",
    "\n",
    "# Use the random grid to search for best hyperparameters\n",
    "# First create the base model to tune\n",
    "rf = RandomForestClassifier(n_estimators= 2,\n",
    "                            #max_features= 'auto',\n",
    "                            max_depth= 2,\n",
    "                            #min_samples_split= 10,\n",
    "                            #min_samples_leaf= 8,\n",
    "                            random_state=42,)\n",
    "\n",
    "\n",
    "#rf.fit(data_ohe_out_X_train, data_ohe_y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NotFittedError",
     "evalue": "This RandomForestClassifier instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotFittedError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-a2be7b02bad1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0my_pred_tr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_ohe_X_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0my_pred_ts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_ohe_X_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclassification_report\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_ohe_y_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_pred_tr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    610\u001b[0m             \u001b[0mThe\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0mclasses\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    611\u001b[0m         \"\"\"\n\u001b[1;32m--> 612\u001b[1;33m         \u001b[0mproba\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    613\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    614\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    652\u001b[0m             \u001b[0mclasses\u001b[0m \u001b[0mcorresponds\u001b[0m \u001b[0mto\u001b[0m \u001b[0mthat\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mattribute\u001b[0m \u001b[1;33m:\u001b[0m\u001b[0mterm\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    653\u001b[0m         \"\"\"\n\u001b[1;32m--> 654\u001b[1;33m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    655\u001b[0m         \u001b[1;31m# Check data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    656\u001b[0m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_X_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_is_fitted\u001b[1;34m(estimator, attributes, msg, all_or_any)\u001b[0m\n\u001b[0;32m    965\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    966\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 967\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mNotFittedError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'name'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    968\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    969\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNotFittedError\u001b[0m: This RandomForestClassifier instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator."
     ]
    }
   ],
   "source": [
    "y_pred_tr = rf.predict(data_ohe_X_train)\n",
    "y_pred_ts = rf.predict(data_ohe_X_test)\n",
    "\n",
    "\n",
    "print(classification_report(data_ohe_y_train,y_pred_tr))\n",
    "print(classification_report(data_ohe_y_test,y_pred_ts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Con el mejor parametro del grid search paso a predecir\n",
    "#y_pred_tr = rf_random.predict(X_train)\n",
    "#accuracy_score = accuracy_score(y_train, y_pred_tr)\n",
    "#precision_score = precision_score(y_train, y_pred_tr)\n",
    "#recall_score = recall_score(y_train, y_pred_tr)\n",
    "#roc_auc_score = roc_auc_score(y_train, y_pred_tr)\n",
    "#lift_score = lift_score(y_train, y_pred_tr)\n",
    "\n",
    "pd.unique(data_ohe_y_train['MonthlyIncome_cat_encode'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from yellowbrick.classifier import ROCAUC\n",
    "\n",
    "visualizer = ROCAUC(rf, classes=[\"0\",\"1\",\"2\",\"3\",\"4\",\"5\",\n",
    "                                 \"6\",\"7\",\"8\",\"9\"])\n",
    "\n",
    "visualizer.fit(data_ohe_out_X_train,data_ohe_out_y_train)\n",
    "visualizer.score(data_ohe_out_X_test,data_ohe_out_y_test)\n",
    "visualizer.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

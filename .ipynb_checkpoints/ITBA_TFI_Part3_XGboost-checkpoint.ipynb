{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRABAJO FINAL INTEGRADOR\n",
    "\n",
    "### NOMBRE: GUIDO PETTINARI\n",
    "\n",
    "### TUTOR: VALERIA SOLIANI\n",
    "\n",
    "### UNIVERSIDAD: INSTITUTO TECNOLOGICO DE BUENOS AIRES (ITBA)\n",
    "\n",
    "**El Trabajo se dividirá en**:\n",
    "\n",
    "    1) Análisis Exploratorio Descriptivo\n",
    "    2) Feature Engineering o Preparación de Datos\n",
    "    3) Modelos Predictivos: Probaremos diferentes algoritmos predictivos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score,precision_score,recall_score,roc_auc_score,make_scorer,f1_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report\n",
    "import xgboost as xgb\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from mlxtend.evaluate import lift_score\n",
    "import csv\n",
    "from funpymodeling.exploratory import status\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load CSVs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_base = pd.read_csv('data_base.csv')\n",
    "data_ohe = pd.read_csv('data_ohe.csv')\n",
    "data_ohe_corr = pd.read_csv('data_ohe_corr.csv')\n",
    "data_ohe_out = pd.read_csv('data_ohe_out.csv')\n",
    "data_ohe_corr_out = pd.read_csv('data_ohe_out_corr.csv')\n",
    "data_out = pd.read_csv('data_out.csv')\n",
    "data_corr = pd.read_csv('data_corr.csv')\n",
    "data_out_corr = pd.read_csv('data_out_corr.csv')\n",
    "data_index = pd.read_csv('data_index.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split All DF in Train and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_base_X = data_base.drop(['MonthlyIncome_cat_encode'],axis=1)\n",
    "data_base_y = data_base[['MonthlyIncome_cat_encode']]\n",
    "data_ohe_X = data_ohe.drop(['MonthlyIncome_cat_encode'],axis=1)\n",
    "data_ohe_y = data_ohe[['MonthlyIncome_cat_encode']]\n",
    "data_ohe_corr_X = data_ohe_corr.drop(['MonthlyIncome_cat_encode'],axis=1)\n",
    "data_ohe_corr_y = data_ohe_corr[['MonthlyIncome_cat_encode']]\n",
    "data_ohe_out_X = data_ohe_out.drop(['MonthlyIncome_cat_encode'],axis=1)\n",
    "data_ohe_out_y = data_ohe_out[['MonthlyIncome_cat_encode']]\n",
    "data_ohe_corr_out_X = data_ohe_corr_out.drop(['MonthlyIncome_cat_encode'],axis=1)\n",
    "data_ohe_corr_out_y = data_ohe_corr_out[['MonthlyIncome_cat_encode']]\n",
    "data_out_X = data_out.drop(['MonthlyIncome_cat_encode'],axis=1)\n",
    "data_out_y = data_out[['MonthlyIncome_cat_encode']]\n",
    "data_corr_X = data_corr.drop(['MonthlyIncome_cat_encode'],axis=1)\n",
    "data_corr_y = data_corr[['MonthlyIncome_cat_encode']]\n",
    "data_out_corr_X = data_out_corr.drop(['MonthlyIncome_cat_encode'],axis=1)\n",
    "data_out_corr_y = data_out_corr[['MonthlyIncome_cat_encode']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_base\n",
    "\n",
    "data_base_X_train, data_base_X_test, data_base_y_train, \\\n",
    "                                     data_base_y_test = train_test_split(data_base_X, data_base_y, test_size=0.3, random_state=42)\n",
    "\n",
    "#data_ohe\n",
    "data_ohe_X_train, data_ohe_X_test, data_ohe_y_train, \\\n",
    "                                   data_ohe_y_test = train_test_split(data_ohe_X, data_ohe_y, test_size=0.3, random_state=42)\n",
    "\n",
    "#data_ohe_corr\n",
    "data_ohe_corr_X_train, data_ohe_corr_X_test, data_ohe_corr_y_train, \\\n",
    "                       data_ohe_corr_y_test = train_test_split(data_ohe_corr_X, data_ohe_corr_y, test_size=0.3, random_state=42)\n",
    "\n",
    "# data_ohe_out\n",
    "data_ohe_out_X_train, data_ohe_out_X_test, data_ohe_out_y_train, \\\n",
    "                      data_ohe_out_y_test = train_test_split(data_ohe_out_X, data_ohe_out_y, test_size=0.3, random_state=42)\n",
    "\n",
    "# data_ohe_corr_out\n",
    "data_ohe_corr_out_X_train, data_ohe_corr_out_X_test, data_ohe_corr_out_y_train, \\\n",
    "                           data_ohe_corr_out_y_test = train_test_split(data_ohe_corr_out_X, data_ohe_corr_out_y, test_size=0.3, random_state=42)\n",
    "\n",
    "# data_out\n",
    "data_out_X_train, data_out_X_test, data_out_y_train, \\\n",
    "                           data_out_y_test = train_test_split(data_out_X, data_out_y, test_size=0.3, random_state=42)\n",
    "\n",
    "# data_corr\n",
    "data_corr_X_train, data_corr_X_test, data_corr_y_train, \\\n",
    "                           data_corr_y_test = train_test_split(data_corr_X, data_corr_y, test_size=0.3, random_state=42)\n",
    "\n",
    "# data_out_corr\n",
    "data_out_corr_X_train, data_out_corr_X_test, data_out_corr_y_train, \\\n",
    "                           data_out_corr_y_test = train_test_split(data_out_corr_X, data_out_corr_y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ohe_X_train.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eta': array([0.1, 0.3, 0.5, 0.7, 0.9]), 'gamma': range(0, 100, 10), 'max_depth': range(3, 10), 'objective': 'multi:softmax', 'seed': 10, 'num_class': 4, 'lambda': range(1, 50, 10), 'alpha': range(1, 50, 10)}\n"
     ]
    }
   ],
   "source": [
    "# Number of trees in random forest\n",
    "# \n",
    "eta = np.arange(0.1,1,0.2)\n",
    "# Maximum number of levels in tree\n",
    "max_depth = range(3, 10, 1)\n",
    "gamma = range(0,100,10)\n",
    "objective='multi:softmax'\n",
    "seed=10\n",
    "num_class=4\n",
    "lambdas = range(1,50,10)\n",
    "alpha =  range(1,50,10)\n",
    "\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = range(2,100,20)\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = range(2,100,20)\n",
    "# Method of selecting samples for training each tree\n",
    "#bootstrap = [True, False]\n",
    "# Create the random grid\n",
    "random_grid = {'eta': eta,\n",
    "               'gamma': gamma,\n",
    "               'max_depth': max_depth,\n",
    "               'objective': objective,\n",
    "               'seed': seed,\n",
    "               'num_class':num_class,\n",
    "               'lambda':lambdas,\n",
    "               'alpha':alpha}\n",
    "               #'bootstrap': bootstrap}\n",
    "print(random_grid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'XGBClassifier' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-c972767ab6de>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;31m# Use the random grid to search for best hyperparameters\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;31m# First create the base model to tune\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mrf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mXGBClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;31m# Random search of parameters, using 3 fold cross validation,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;31m# search across 100 different combinations, and use all available cores\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'XGBClassifier' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "scoring = {'lift':make_scorer(lift_score),\n",
    "           'precision': make_scorer(precision_score, average = 'macro'),\n",
    "           'f1_score':make_scorer(f1_score, average='macro'),\n",
    "           'accuracy': make_scorer(accuracy_score),\n",
    "           'recall':make_scorer(recall_score,average='macro'),\n",
    "           'roc_auc_ovr':'roc_auc_ovr'}\n",
    "\n",
    "# Use the random grid to search for best hyperparameters\n",
    "# First create the base model to tune\n",
    "rf = XGBClassifier()\n",
    "# Random search of parameters, using 3 fold cross validation, \n",
    "# search across 100 different combinations, and use all available cores\n",
    "rf_random = GridSearchCV(estimator = rf, \n",
    "                               param_grid = random_grid,\n",
    "                               scoring = scoring,\n",
    "                               refit='lift',\n",
    "                               cv = 5, \n",
    "                               verbose=1, \n",
    "                               n_jobs = -1)\n",
    "\n",
    "\n",
    "# list dataframes train that Random Forest accepts\n",
    "list_dataframes_train = [#[data_base_X_train, data_base_X_test],\n",
    "                         [data_ohe_X_train, data_ohe_y_train],\n",
    "                         [data_ohe_corr_X_train, data_ohe_corr_y_train],\n",
    "                         [data_ohe_out_X_train, data_ohe_out_y_train],\n",
    "                         [data_ohe_corr_out_X_train, data_ohe_corr_out_y_train]\n",
    "                         #[data_out_X, data_out_y],\n",
    "                         #[data_corr_X, data_corr_y],\n",
    "                         #[data_out_corr_X, data_out_corr_y]\n",
    "                         ]\n",
    "\n",
    "# list dataframes train that Random Forest accepts\n",
    "list_dataframes_test = [#[data_base_X_train, data_base_X_test],\n",
    "                         [data_ohe_X_test, data_ohe_y_test],\n",
    "                         [data_ohe_corr_X_test, data_ohe_corr_y_test],\n",
    "                         [data_ohe_out_X_test, data_ohe_out_y_test],\n",
    "                         [data_ohe_corr_out_X_test, data_ohe_corr_out_y_test]\n",
    "                         #[data_out_X, data_out_y],\n",
    "                         #[data_corr_X, data_corr_y],\n",
    "                         #[data_out_corr_X, data_out_corr_y]\n",
    "                         ]\n",
    "\n",
    "\n",
    "list_dataframes_names = ['data_ohe','data_ohe_corr','data_ohe_out','data_ohe_corr_out']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Fit the random search model\n",
    "df = pd.DataFrame()\n",
    "for i in range(0,len(list_dataframes_train)):\n",
    "    #Entreno sobre mis dataframes train  \n",
    "    rf_random.fit(list_dataframes_train[i][0], list_dataframes_train[i][1].values.ravel())\n",
    "    len_name = len(rf_random.cv_results_['mean_test_accuracy'])\n",
    "    name = [list_dataframes_names[i]]*len_name\n",
    "\n",
    "    train_results = pd.concat([\n",
    "                     pd.DataFrame(name,columns=['dataframe']),\n",
    "                     pd.DataFrame(rf_random.cv_results_['params']),\n",
    "                     pd.DataFrame(rf_random.cv_results_['mean_test_lift'],columns=['lift']),          \n",
    "                     pd.DataFrame(rf_random.cv_results_['mean_test_accuracy'],columns=['accuracy']),\n",
    "                     pd.DataFrame(rf_random.cv_results_['mean_test_precision'],columns=['precision_score']),\n",
    "                     pd.DataFrame(rf_random.cv_results_['mean_test_recall'],columns=['recall']),\n",
    "                     pd.DataFrame(rf_random.cv_results_['mean_test_f1_score'],columns=['f1_score']),\n",
    "                     pd.DataFrame(rf_random.cv_results_['mean_test_roc_auc_ovr'],columns=['roc_auc_ovr'])],axis=1).sort_values('lift',ascending=False)\n",
    "    df = df.append(train_results) \n",
    "df.to_csv('train_rf_results_v3.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A continuación correremos con los parametros que nos dió mejor resultado tanto el training como el testing y los graficaremos \n",
    "# con una curva de ROC\n",
    "\n",
    "# Use the random grid to search for best hyperparameters\n",
    "# First create the base model to tune\n",
    "rf = RandomForestClassifier(n_estimators= 52,\n",
    "                            max_features= 'auto',\n",
    "                            max_depth= 28,\n",
    "                            min_samples_split= 22,\n",
    "                            min_samples_leaf= 2,\n",
    "                            random_state=42,)\n",
    "\n",
    "\n",
    "rf.fit(data_ohe_X_train, data_ohe_y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_pred_tr = rf.predict(data_ohe_X_train)\n",
    "y_pred_ts = rf.predict(data_ohe_X_test)\n",
    "\n",
    "\n",
    "print(classification_report(data_ohe_y_train,y_pred_tr))\n",
    "print(classification_report(data_ohe_y_test,y_pred_ts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Con el mejor parametro del grid search paso a predecir\n",
    "#y_pred_tr = rf_random.predict(X_train)\n",
    "#accuracy_score = accuracy_score(y_train, y_pred_tr)\n",
    "#precision_score = precision_score(y_train, y_pred_tr)\n",
    "#recall_score = recall_score(y_train, y_pred_tr)\n",
    "#roc_auc_score = roc_auc_score(y_train, y_pred_tr)\n",
    "#lift_score = lift_score(y_train, y_pred_tr)\n",
    "\n",
    "pd.unique(data_ohe_y_train['MonthlyIncome_cat_encode'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from yellowbrick.classifier import ROCAUC,PrecisionRecallCurve,ClassBalance\n",
    "from yellowbrick.target import FeatureCorrelation\n",
    "\n",
    "visualizer = ROCAUC(rf, classes=[\"0\",\"1\",\"2\",\"3\",\"4\",\"5\",\n",
    "                                 \"6\",\"7\",\"8\",\"9\"])\n",
    "\n",
    "visualizer.fit(data_ohe_X_train,data_ohe_y_train)\n",
    "visualizer.score(data_ohe_X_test,data_ohe_y_test)\n",
    "visualizer.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
